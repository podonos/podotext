"""
ASR Inference Script using Whisper Large v3 Turbo

- Model: openai/whisper-large-v3-turbo
- Source: https://huggingface.co/openai/whisper-large-v3-turbo
- Description: 
    - This script performs automatic speech recognition (ASR) on pre-synthesized audio files (TTS outputs) using the pretrained wav2vec ASR model.
    - It loads URLs pointing to audio files generated from different TTS systems (chatterbox, kokoro, melo, etc.), transcribes them, and appends the results to their respective DataFrames.
- DataFrame: 
    - The DataFrame contains both the original text and the file paths of the WAV files generated by the TTS model.
    - Ex) df_kokoro contains the original text along with the file paths of the WAV files generated from that text. 
    
- Output: The transcriptions are saved into new columns named 'whisper' and exported as CSV files for further evaluation (e.g., WER/CER calculation).
"""

# Import necessary libraries
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from datasets import load_dataset
import torch
import pandas as pd
import time
import torchaudio
from tqdm import tqdm

# Set device and precision
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

# Load Whisper model and processor
model_id = "openai/whisper-large-v3-turbo"
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id,
    torch_dtype=torch_dtype,
    low_cpu_mem_usage=True,
    use_safetensors=True
).to(device)

processor = AutoProcessor.from_pretrained(model_id)

# Create ASR inference pipeline
pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
)

# Inference function that takes a local audio file path and returns transcription
def make_asr_script(url):
    result = pipe(url)
    transcription = result["text"]
    return transcription


# === ASR Inference: Chatterbox ===
df_chatterbox = pd.read_csv("")

scription_list = []
for i in tqdm(range(df_chatterbox.shape[0])):
    temp_url = df_chatterbox.iloc[i,3]  # Assuming column 3 has local file paths
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

if df_chatterbox.shape[0] == len(scription_list):
    df_chatterbox['whisper'] = scription_list

df_chatterbox.to_csv("", index=False, encoding="utf-8-sig")


# === ASR Inference: Kokoro ===
df_kokoro = pd.read_csv("")

scription_list = []
for i in tqdm(range(df_kokoro.shape[0])):
    temp_url = df_kokoro.iloc[i, 3]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

if df_kokoro.shape[0] == len(scription_list):
    df_kokoro['whisper'] = scription_list

df_kokoro.to_csv("", index=False, encoding="utf-8-sig")


# === ASR Inference: melo ===
df_melo = pd.read_csv("")

scription_list = []
for i in tqdm(range(df_melo.shape[0])):
    temp_url = df_melo.iloc[i, 3]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

if df_melo.shape[0] == len(scription_list):
    df_melo['whisper'] = scription_list

df_melo.to_csv("", index=False, encoding="utf-8-sig")


# === ASR Inference: Outetts ===
df_outetts = pd.read_csv("")
scription_list = []
for i in tqdm(range(df_outetts.shape[0])):
    temp_url = df_outetts.iloc[i, 1]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)
if df_outetts.shape[0] == len(scription_list):
    df_outetts['whisper'] = scription_list
df_outetts.to_csv("", index=False, encoding="utf-8-sig")
