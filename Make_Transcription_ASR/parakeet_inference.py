"""
ASR Inference Script using NVIDIA Parakeet (parakeet-tdt-0.6b-v2)

- Model: NVIDIA Parakeet TDT 0.6B v2 (ASR)
- Source: https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2
- Description: 
    - This script performs automatic speech recognition (ASR) on pre-synthesized audio files (TTS outputs) using the pretrained parakeet ASR model.
    - It loads URLs pointing to audio files generated from different TTS systems (chatterbox, kokoro, melo, etc.), transcribes them, and appends the results to their respective DataFrames.
    
- DataFrame: 
    - The DataFrame contains both the original text and the file paths of the WAV files generated by the TTS model.
    - Ex) df_kokoro contains the original text along with the file paths of the WAV files generated from that text. 

- Output: The transcriptions are saved into new columns named 'parakeet' and exported as CSV files for further evaluation (e.g., WER/CER calculation).
"""
# Import necessary libraries
import nemo.collections.asr as nemo_asr
import pandas as pd

# Load the pretrained pakket ASR model from NVIDIA
asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name="nvidia/parakeet-tdt-0.6b-v2")

# Define a helper function that transcribes a given audio URL
def make_asr_script(url):
    transcription = asr_model.transcribe([url])  
    transcription = transcription[0].text        
    transcription = transcription.strip()        
    return transcription


# === ASR Inference: Chatterbox ===
df_chatterbox = pd.read_csv("")

from tqdm import tqdm
scription_list = []

# Run ASR on each audio file
for i in tqdm(range(df_chatterbox.shape[0])):
    temp_url = df_chatterbox.iloc[i, 3]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

# Save transcriptions if lengths match
if df_chatterbox.shape[0] == len(scription_list):
    df_chatterbox['pakket'] = scription_list


# === ASR Inference: Kokoro ===
df_kokoro = pd.read_csv("")

scription_list = []
for i in tqdm(range(df_kokoro.shape[0])):
    temp_url = df_kokoro.iloc[i, 3]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

if df_kokoro.shape[0] == len(scription_list):
    df_kokoro['pakket'] = scription_list


# === ASR Inference: Melo ===
df_melo = pd.read_csv("")

scription_list = []
for i in tqdm(range(df_melo.shape[0])):
    temp_url = df_melo.iloc[i, 3]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)

if df_melo.shape[0] == len(scription_list):
    df_melo['pakket'] = scription_list


# === ASR Inference: Outetts ===
df_outetts = pd.read_csv("")
scription_list = []
for i in tqdm(range(df_outetts.shape[0])):
    temp_url = df_outetts.iloc[i, 1]
    scription_temp = make_asr_script(temp_url)
    scription_list.append(scription_temp)
if df_outetts.shape[0] == len(scription_list):
    df_outetts['pakket'] = scription_list


# === Save all transcribed results to CSV ===
df_chatterbox.to_csv("/disk1/ywchoi/ASRU2025_datapaper/legal/pakket_folder/df_chatterbox_pakket.csv", index=False, encoding="utf-8-sig")
df_kokoro.to_csv("/disk1/ywchoi/ASRU2025_datapaper/legal/pakket_folder/df_kokoro_pakket.csv", index=False, encoding="utf-8-sig")
df_melo.to_csv("/disk1/ywchoi/ASRU2025_datapaper/legal/pakket_folder/df_melo_pakket.csv", index=False, encoding="utf-8-sig")
df_outetts.to_csv("/disk1/ywchoi/ASRU2025_datapaper/legal/pakket_folder/df_outetts_pakket_v2.csv", index=False, encoding="utf-8-sig")
